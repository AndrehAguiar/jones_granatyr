{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução ao spaCy\n",
    "# Etapa 1: Instalação do spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy --upgrade\n",
    "#!pip install spacy==2.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pt_core_news_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-2.2.5/pt_core_news_sm-2.2.5.tar.gz#egg=pt_core_news_sm==2.2.5 in c:\\programdata\\anaconda3\\envs\\nlp_spacy\\lib\\site-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in c:\\programdata\\anaconda3\\envs\\nlp_spacy\\lib\\site-packages (from pt_core_news_sm==2.2.5) (2.2.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in c:\\programdata\\anaconda3\\envs\\nlp_spacy\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\programdata\\anaconda3\\envs\\nlp_spacy\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.9.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\programdata\\anaconda3\\envs\\nlp_spacy\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.8.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\envs\\nlp_spacy\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.0.5)\n",
      "Requirement already satisfied: thinc<7.4.0,>=7.3.0 in c:\\programdata\\anaconda3\\envs\\nlp_spacy\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (7.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\envs\\nlp_spacy\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (49.6.0.post20201009)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\programdata\\anaconda3\\envs\\nlp_spacy\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\programdata\\anaconda3\\envs\\nlp_spacy\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.19.4)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\programdata\\anaconda3\\envs\\nlp_spacy\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\envs\\nlp_spacy\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.25.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\programdata\\anaconda3\\envs\\nlp_spacy\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.0.5)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in c:\\programdata\\anaconda3\\envs\\nlp_spacy\\lib\\site-packages (from spacy>=2.2.2->pt_core_news_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in c:\\programdata\\anaconda3\\envs\\nlp_spacy\\lib\\site-packages (from thinc<7.4.0,>=7.3.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (4.54.1)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in c:\\programdata\\anaconda3\\envs\\nlp_spacy\\lib\\site-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\nlp_spacy\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\programdata\\anaconda3\\envs\\nlp_spacy\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\envs\\nlp_spacy\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\nlp_spacy\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->pt_core_news_sm==2.2.5) (1.26.2)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\programdata\\anaconda3\\envs\\nlp_spacy\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in c:\\programdata\\anaconda3\\envs\\nlp_spacy\\lib\\site-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->pt_core_news_sm==2.2.5) (3.7.4.3)\n",
      "Link simb¢lico criado para C:\\ProgramData\\Anaconda3\\envs\\nlp_spacy\\lib\\site-packages\\spacy\\data\\pt <<===>> C:\\ProgramData\\Anaconda3\\envs\\nlp_spacy\\lib\\site-packages\\pt_core_news_sm\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('pt_core_news_sm')\n",
      "[+] Linking successful\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlp_spacy\\lib\\site-packages\\pt_core_news_sm -->\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlp_spacy\\lib\\site-packages\\spacy\\data\\pt\n",
      "You can now load the model via spacy.load('pt')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.1; however, version 20.3.3 is available.\n",
      "You should consider upgrading via the 'C:\\ProgramData\\Anaconda3\\envs\\nlp_spacy\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Etapa 2: Marcação POS\n",
    "\n",
    "- POS (part-of-speech) atribui para as palavras partes da fala, como substantivos, adjetivos, verbos\n",
    "- Importante para a detecção de entidades no texto, pois primeiro é necessário saber o que o texto contém\n",
    "- Lista de tokens: https://spacy.io/api/annotation#pos-tagging\n",
    "- Português: https://www.sketchengine.eu/portuguese-freeling-part-of-speech-tagset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.pt.Portuguese at 0x1e99b20cb48>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pln = spacy.load('pt')\n",
    "pln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estou AUX\n",
      "aprendendo VERB\n",
      "processamento NOUN\n",
      "de ADP\n",
      "linguagem NOUN\n",
      "natural ADJ\n",
      ", PUNCT\n",
      "curso NOUN\n",
      "Curitiba PROPN\n"
     ]
    }
   ],
   "source": [
    "doc = pln('Estou aprendendo processamento de linguagem natural, curso Curitiba')\n",
    "for token in doc:\n",
    "    print(token.text, token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Legenda \n",
    "\n",
    "- lemma: raiz da palavra\n",
    "- pos: parte da fala\n",
    "- tag: informações morfológicas, como se o verbo está no passado\n",
    "- dep: dependência sintática\n",
    "- shape: formato (maiúsculo, minúsculo, dígitos)\n",
    "- alpha: se é alfabético\n",
    "- stop: se é stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estou Estou AUX <aux>|V|PR|1S|IND|@FS-STA aux Xxxxx True True\n",
      "aprendendo aprender VERB <mv>|V|GER|@ICL-AUX< ROOT xxxx True False\n",
      "processamento processamento NOUN <np-idf>|N|M|S|@<ACC obj xxxx True False\n",
      "de de ADP PRP|@N< case xx True True\n",
      "linguagem linguagem NOUN <np-idf>|N|F|S|@P< nmod xxxx True False\n",
      "natural natural ADJ ADJ|F|S|@N< amod xxxx True False\n",
      ", , PUNCT PU|@PU punct , False False\n",
      "curso cursar NOUN <np-idf>|N|F|S|@N<PRED appos xxxx True False\n",
      "Curitiba Curitiba PROPN PROP|M|S|@N< appos Xxxxx True False\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.lemma_, token.pos_, token.tag_,\n",
    "         token.dep_, token.shape_, token.is_alpha, token.is_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curitiba\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    if token.pos_ == 'PROPN':\n",
    "        print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Etapa 3: Lematização e stemização\n",
    "\n",
    "- Lematização: \"Lema\" de uma palavra de acordo com seu significado no dicionário - palavra base (análise vocabular e morfológica)\n",
    "- Stemização: Extrair o radical das palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estou Estou\n",
      "aprendendo aprender\n",
      "processamento processamento\n",
      "de de\n",
      "linguagem linguagem\n",
      "natural natural\n",
      ", ,\n",
      "curso cursar\n",
      "Curitiba Curitiba\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Estou',\n",
       " 'aprender',\n",
       " 'processamento',\n",
       " 'de',\n",
       " 'linguagem',\n",
       " 'natural',\n",
       " ',',\n",
       " 'cursar',\n",
       " 'Curitiba']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1 = pln('encontrei encontraram encontrarão encontrariam')\n",
    "[token.lemma_ for token in doc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Comparação stemização (NLTK) x lematização (spaCy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package rslp to C:\\Users\\TOP\n",
      "[nltk_data]     Artes\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aprend'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = nltk.stem.RSLPStemmer()\n",
    "stemmer.stem('aprendendo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estou Estou est\n",
      "aprendendo aprender aprend\n",
      "processamento processamento process\n",
      "de de de\n",
      "linguagem linguagem lingu\n",
      "natural natural natur\n",
      ", , ,\n",
      "curso cursar curs\n",
      "Curitiba Curitiba curitib\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.lemma_, stemmer.stem(token.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Etapa 4: Reconhecimento de entidades nomeadas\n",
    "\n",
    "- NER (Named-Entity Recognition)\n",
    "- Encontrar e classificar entidades no texto, dependendo da base de dados que foi utilizada para o treinamento (pessoa, localização, empresa, numéricos)\n",
    "- Usado em chatbots para saber o assunto falado\n",
    "- Siglas: https://spacy.io/api/annotation#named-entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = 'A IBM é uma empresa dos Estados Unidos voltada para a área de informática. Sua sede no Brasil fica em São Paulo e a receita em 2018 foi de aproximadamente 320 bilhões de reais'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IBM ORG\n",
      "Estados Unidos LOC\n",
      "Brasil LOC\n",
      "São Paulo LOC\n"
     ]
    }
   ],
   "source": [
    "documento = pln(texto)\n",
    "for entidade in documento.ents:\n",
    "    print(entidade.text, entidade.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">A \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    IBM\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " é uma empresa dos \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Estados Unidos\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " voltada para a área de informática. Sua sede no \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brasil\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " fica em \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    São Paulo\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " e a receita em 2018 foi de aproximadamente 320 bilhões de reais</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(documento, style = 'ent', jupyter = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = 'Bill Gates nasceu em Seattle em 28/10/1995 e foi o criador da Microsoft'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bill Gates PER\n",
      "Seattle LOC\n",
      "Microsoft ORG\n"
     ]
    }
   ],
   "source": [
    "documento =pln(texto)\n",
    "for entidade in documento.ents:\n",
    "    print(entidade.text, entidade.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Bill Gates\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " nasceu em \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Seattle\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       " em 28/10/1995 e foi o criador da \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Microsoft\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(documento, style = 'ent', jupyter = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bill Gates\n"
     ]
    }
   ],
   "source": [
    "for entidade in documento.ents:\n",
    "    if entidade.label_ == 'PER':\n",
    "        print(entidade.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Etapa 5: Stopwords\n",
    "- Palavras que aparecem com muita frequência e que não apresentam muito significado (e, a, de, da, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.pt.stop_words import STOP_WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pois', 'fazia', 'lá', 'porque', 'mas', 'fomos', 'saber', 'usar', 'sabe', 'da', 'naquela', 'grupo', 'inicio', 'longe', 'aquilo', 'conhecido', 'um', 'porém', 'esse', 'fazemos', 'quieta', 'questão', 'perto', 'possível', 'todas', 'cima', 'meio', 'dentro', 'vinda', 'sois', 'entre', 'dão', 'portanto', 'poder', 'pelos', 'também', 'estas', 'sete', 'pegar', 'quem', 'algo', 'estava', 'cá', 'tentei', 'fostes', 'pelo', 'momento', 'nesse', 'terceiro', 'cujo', 'desta', 'das', 'até', 'dez', 'certamente', 'fim', 'quer', 'relação', 'umas', 'tempo', 'quinto', 'sob', 'máximo', 'pôde', 'ademais', 'em', 'tudo', 'apontar', 'aí', 'sua', 'nessa', 'qualquer', 'sexta', 'exemplo', 'adeus', 'segundo', 'vossas', 'duas', 'outra', 'do', 'é', 'nuns', 'área', 'isso', 'fazer', 'dar', 'no', 'puderam', 'aquele', 'próxima', 'número', 'esteve', 'muitos', 'ele', 'minhas', 'assim', 'baixo', 'as', 'novas', 'quais', 'novos', 'tens', 'quero', 'quanto', 'esta', 'fará', 'lugar', 'pelas', 'tiveste', 'teu', 'tanto', 'nunca', 'apenas', 'seria', 'irá', 'maiorias', 'pontos', 'seis', 'fazeis', 'possivelmente', 'catorze', 'demais', 'estivemos', 'menos', 'uns', 'mil', 'somos', 'ora', 'aquelas', 'usa', 'tarde', 'atrás', 'tua', 'teus', 'ao', 'pela', 'ela', 'geral', 'conhecida', 'sei', 'desde', 'embora', 'toda', 'estará', 'breve', 'minha', 'fui', 'doze', 'podia', 'dezasseis', 'muito', 'seus', 'têm', 'mais', 'cuja', 'vem', 'dezanove', 'tem', 'ponto', 'então', 'meses', 'maior', 'ontem', 'mês', 'foste', 'vezes', 'des', 'vós', 'pouco', 'à', 'na', 'te', 'dezassete', 'fora', 'pouca', 'és', 'terceira', 'bem', 'sétima', 'dos', 'quarta', 'aqui', 'tuas', 'próximo', 'meus', 'essa', 'vêm', 'apoio', 'não', 'iniciar', 'já', 'eles', 'tais', 'antes', 'querem', 'zero', 'sétimo', 'vai', 'final', 'primeiro', 'naquele', 'tu', 'favor', 'povo', 'tal', 'comprido', 'sempre', 'numa', 'veja', 'nesta', 'maioria', 'for', 'apoia', 'comprida', 'quarto', 'vossos', 'seu', 'algumas', 'oitava', 'para', 'sem', 'sim', 'lado', 'estive', 'forma', 'tentar', 'devem', 'aquela', 'mal', 'me', 'de', 'neste', 'suas', 'desse', 'temos', 'todo', 'alguns', 'você', 'outros', 'que', 'faço', 'essas', 'tenho', 'tanta', 'vos', 'nível', 'elas', 'caminho', 'tipo', 'parece', 'acerca', 'dizem', 'vais', 'ser', 'quinze', 'bom', 'direita', 'nenhuma', 'vosso', 'depois', 'custa', 'daquela', 'estiveram', 'vez', 'tão', 'se', 'aqueles', 'certeza', 'contra', 'esses', 'estou', 'talvez', 'ou', 'qual', 'onze', 'inclusive', 'foi', 'bastante', 'cedo', 'põem', 'novo', 'ambas', 'grande', 'oito', 'eu', 'sobre', 'disso', 'nós', 'falta', 'primeira', 'tendes', 'segunda', 'obrigado', 'sou', 'nossos', 'sistema', 'vão', 'vinte', 'porquê', 'nem', 'ver', 'quinta', 'posso', 'todos', 'quê', 'enquanto', 'através', 'ir', 'dizer', 'tiveram', 'vens', 'dezoito', 'eventual', 'nas', 'cada', 'deverá', 'local', 'nossa', 'tive', 'quieto', 'só', 'ter', 'estes', 'cinco', 'dois', 'após', 'como', 'somente', 'ali', 'fez', 'lhe', 'vindo', 'dessa', 'nove', 'números', 'dá', 'porquanto', 'vossa', 'por', 'tentaram', 'nova', 'conselho', 'treze', 'valor', 'às', 'estado', 'isto', 'este', 'nada', 'próprio', 'diz', 'sexto', 'ligado', 'tivemos', 'meu', 'está', 'último', 'quando', 'além', 'tente', 'são', 'corrente', 'nosso', 'estás', 'partir', 'quatro', 'poderá', 'obrigada', 'posição', 'vários', 'foram', 'logo', 'nos', 'num', 'uma', 'onde', 'cento', 'menor', 'era', 'ambos', 'diante', 'fazem', 'podem', 'agora', 'põe', 'outras', 'estar', 'estiveste', 'fazes', 'parte', 'pode', 'nossas', 'com', 'grandes', 'coisa', 'oitavo', 'faz', 'boa', 'aos', 'três', 'contudo', 'os', 'vocês', 'tivestes', 'ainda', 'estivestes', 'teve', 'deve', 'daquele', 'deste', 'estão', 'mesmo', 'debaixo'}\n"
     ]
    }
   ],
   "source": [
    "print(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "413"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pln.vocab['ir'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pln.vocab['caminhar'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento:\n",
      "Estou aprendendo processamento de linguagem natural, curso Curitiba\n",
      "\n",
      "\n",
      "aprendendo\n",
      "processamento\n",
      "linguagem\n",
      "natural\n",
      ",\n",
      "curso\n",
      "Curitiba\n"
     ]
    }
   ],
   "source": [
    "print(f'Documento:\\n{doc}\\n\\n')\n",
    "for token in doc:\n",
    "    if not pln.vocab[token.text].is_stop:\n",
    "        print(token.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Etapa 6: Parsing de dependências\n",
    "\n",
    "- Relação pai-filho entre as palavras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "documento = pln('reserve uma passagem saindo de Guarulhos e chegando em Curitiba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Guarulhos, Curitiba)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origem = documento[5]\n",
    "destino = documento[9]\n",
    "origem, destino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[passagem, reserve]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(origem.ancestors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[chegando, reserve]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(destino.ancestors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documento[0].is_ancestor(documento[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Guarulhos': [passagem, reserve], 'Curitiba': [chegando, reserve]}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locais = {token.text:list(token.ancestors) for token in documento if token.pos_ == 'PROPN'}\n",
    "locais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "documento = pln('Reserva de uma mesa para o restaurante e de um táxi para o hotel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((mesa, táxi), (restaurante, hotel))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tarefas = documento[3], documento[10]\n",
    "locais = documento[6], documento[13]\n",
    "tarefas, locais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- restaurante\n",
      "mesa\n",
      "Reserva\n",
      "------- hotel\n",
      "táxi\n",
      "restaurante\n",
      "mesa\n",
      "Reserva\n"
     ]
    }
   ],
   "source": [
    "for local in locais:\n",
    "    print('-------', local)\n",
    "    for objeto in local.ancestors:\n",
    "        print(objeto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reserva de mesa é para o restaurante\n",
      "Reserva de táxi é para o hotel\n"
     ]
    }
   ],
   "source": [
    " for local in locais:\n",
    "    for objeto in local.ancestors:\n",
    "        if objeto in tarefas:\n",
    "            print(f'Reserva de {objeto} é para o {local}')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(restaurante, [para, o, táxi])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documento[6], list(documento[6].children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"pt\" id=\"2c78609f8a864b8f8e04c22dfcdace93-0\" class=\"displacy\" width=\"1310\" height=\"317.0\" direction=\"ltr\" style=\"max-width: none; height: 317.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Reserva</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">de</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">uma</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">mesa</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">para</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">o</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">restaurante</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">e</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">de</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"860\">um</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"860\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">táxi</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">para</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1130\">o</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1130\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1220\">hotel</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1220\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c78609f8a864b8f8e04c22dfcdace93-0-0\" stroke-width=\"2px\" d=\"M160,182.0 C160,92.0 310.0,92.0 310.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c78609f8a864b8f8e04c22dfcdace93-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M160,184.0 L152,172.0 168,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c78609f8a864b8f8e04c22dfcdace93-0-1\" stroke-width=\"2px\" d=\"M250,182.0 C250,137.0 305.0,137.0 305.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c78609f8a864b8f8e04c22dfcdace93-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M250,184.0 L242,172.0 258,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c78609f8a864b8f8e04c22dfcdace93-0-2\" stroke-width=\"2px\" d=\"M70,182.0 C70,47.0 315.0,47.0 315.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c78609f8a864b8f8e04c22dfcdace93-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M315.0,184.0 L323.0,172.0 307.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c78609f8a864b8f8e04c22dfcdace93-0-3\" stroke-width=\"2px\" d=\"M430,182.0 C430,92.0 580.0,92.0 580.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c78609f8a864b8f8e04c22dfcdace93-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M430,184.0 L422,172.0 438,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c78609f8a864b8f8e04c22dfcdace93-0-4\" stroke-width=\"2px\" d=\"M520,182.0 C520,137.0 575.0,137.0 575.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c78609f8a864b8f8e04c22dfcdace93-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M520,184.0 L512,172.0 528,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c78609f8a864b8f8e04c22dfcdace93-0-5\" stroke-width=\"2px\" d=\"M340,182.0 C340,47.0 585.0,47.0 585.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c78609f8a864b8f8e04c22dfcdace93-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M585.0,184.0 L593.0,172.0 577.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c78609f8a864b8f8e04c22dfcdace93-0-6\" stroke-width=\"2px\" d=\"M700,182.0 C700,47.0 945.0,47.0 945.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c78609f8a864b8f8e04c22dfcdace93-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M700,184.0 L692,172.0 708,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c78609f8a864b8f8e04c22dfcdace93-0-7\" stroke-width=\"2px\" d=\"M790,182.0 C790,92.0 940.0,92.0 940.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c78609f8a864b8f8e04c22dfcdace93-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M790,184.0 L782,172.0 798,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c78609f8a864b8f8e04c22dfcdace93-0-8\" stroke-width=\"2px\" d=\"M880,182.0 C880,137.0 935.0,137.0 935.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c78609f8a864b8f8e04c22dfcdace93-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M880,184.0 L872,172.0 888,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c78609f8a864b8f8e04c22dfcdace93-0-9\" stroke-width=\"2px\" d=\"M610,182.0 C610,2.0 950.0,2.0 950.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c78609f8a864b8f8e04c22dfcdace93-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M950.0,184.0 L958.0,172.0 942.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c78609f8a864b8f8e04c22dfcdace93-0-10\" stroke-width=\"2px\" d=\"M1060,182.0 C1060,92.0 1210.0,92.0 1210.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c78609f8a864b8f8e04c22dfcdace93-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1060,184.0 L1052,172.0 1068,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c78609f8a864b8f8e04c22dfcdace93-0-11\" stroke-width=\"2px\" d=\"M1150,182.0 C1150,137.0 1205.0,137.0 1205.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c78609f8a864b8f8e04c22dfcdace93-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1150,184.0 L1142,172.0 1158,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-2c78609f8a864b8f8e04c22dfcdace93-0-12\" stroke-width=\"2px\" d=\"M970,182.0 C970,47.0 1215.0,47.0 1215.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-2c78609f8a864b8f8e04c22dfcdace93-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1215.0,184.0 L1223.0,172.0 1207.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualização local\n",
    "# displacy.serve(documento, style='dep')\n",
    "\n",
    "displacy.render(documento, style='dep', jupyter=True, options = {'distance':90})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(mesa, [Reserva], [de, uma, restaurante])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documento[3], list(documento[3].ancestors), list(documento[3].children)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((Curitiba, Guarulhos), (visitar, ficar))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documento = pln('Quais locais podemos visitar em Curitiba e para ficar em Guarulhos?')\n",
    "lugares = documento[5], documento[10]\n",
    "acoes = documento[3], documento[8]\n",
    "lugares, acoes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curitiba para visitar\n",
      "Guarulhos para ficar\n"
     ]
    }
   ],
   "source": [
    "for local in lugares:\n",
    "    for acao in local.ancestors:\n",
    "        if acao.pos_ == 'VERB':\n",
    "            print(f'{local} para {acao}')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"pt\" id=\"e549d0a74c7949bea2aeff4efd30731e-0\" class=\"displacy\" width=\"1040\" height=\"317.0\" direction=\"ltr\" style=\"max-width: none; height: 317.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Quais</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">locais</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">podemos</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">visitar</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">em</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">Curitiba</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">e</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">CCONJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">para</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">ficar</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"860\">em</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"860\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">Guarulhos?</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e549d0a74c7949bea2aeff4efd30731e-0-0\" stroke-width=\"2px\" d=\"M70,182.0 C70,47.0 315.0,47.0 315.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e549d0a74c7949bea2aeff4efd30731e-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,184.0 L62,172.0 78,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e549d0a74c7949bea2aeff4efd30731e-0-1\" stroke-width=\"2px\" d=\"M70,182.0 C70,137.0 125.0,137.0 125.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e549d0a74c7949bea2aeff4efd30731e-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M125.0,184.0 L133.0,172.0 117.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e549d0a74c7949bea2aeff4efd30731e-0-2\" stroke-width=\"2px\" d=\"M250,182.0 C250,137.0 305.0,137.0 305.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e549d0a74c7949bea2aeff4efd30731e-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M250,184.0 L242,172.0 258,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e549d0a74c7949bea2aeff4efd30731e-0-3\" stroke-width=\"2px\" d=\"M430,182.0 C430,137.0 485.0,137.0 485.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e549d0a74c7949bea2aeff4efd30731e-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M430,184.0 L422,172.0 438,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e549d0a74c7949bea2aeff4efd30731e-0-4\" stroke-width=\"2px\" d=\"M340,182.0 C340,92.0 490.0,92.0 490.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e549d0a74c7949bea2aeff4efd30731e-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M490.0,184.0 L498.0,172.0 482.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e549d0a74c7949bea2aeff4efd30731e-0-5\" stroke-width=\"2px\" d=\"M610,182.0 C610,92.0 760.0,92.0 760.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e549d0a74c7949bea2aeff4efd30731e-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M610,184.0 L602,172.0 618,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e549d0a74c7949bea2aeff4efd30731e-0-6\" stroke-width=\"2px\" d=\"M700,182.0 C700,137.0 755.0,137.0 755.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e549d0a74c7949bea2aeff4efd30731e-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">mark</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M700,184.0 L692,172.0 708,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e549d0a74c7949bea2aeff4efd30731e-0-7\" stroke-width=\"2px\" d=\"M340,182.0 C340,2.0 770.0,2.0 770.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e549d0a74c7949bea2aeff4efd30731e-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770.0,184.0 L778.0,172.0 762.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e549d0a74c7949bea2aeff4efd30731e-0-8\" stroke-width=\"2px\" d=\"M880,182.0 C880,137.0 935.0,137.0 935.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e549d0a74c7949bea2aeff4efd30731e-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M880,184.0 L872,172.0 888,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e549d0a74c7949bea2aeff4efd30731e-0-9\" stroke-width=\"2px\" d=\"M790,182.0 C790,92.0 940.0,92.0 940.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e549d0a74c7949bea2aeff4efd30731e-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M940.0,184.0 L948.0,172.0 932.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(documento, style='dep', jupyter=True, options = {'distance':90})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 7: Semelhanças entre palavras e frases\n",
    "\n",
    "- Verificar se duas palavras são semelhantes ou logicamente relacionadas\n",
    "- Usa o algoritmo GloVe (Global Vectors for Word Representation)\n",
    "- Artigo original: https://nlp.stanford.edu/pubs/glove.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1 = pln('olá')\n",
    "p2 = pln('oi')\n",
    "p3 = pln('ou')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlp_spacy\\lib\\runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8258470579501752"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.similarity(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlp_spacy\\lib\\runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8258470579501752"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2.similarity(p1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlp_spacy\\lib\\runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5566860985026827"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1.similarity(p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlp_spacy\\lib\\runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5912282624717209"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2.similarity(p3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlp_spacy\\lib\\runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8939301045295635"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto1 = pln('Quando será lançado o novo filme?')\n",
    "texto2 = pln('Quando será o lançamento do novo filme?')\n",
    "texto3 = pln('O novo filme será lançado o mês que vem')\n",
    "texto4 = pln('Qual a cor do carro?')\n",
    "texto1.similarity(texto2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlp_spacy\\lib\\runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7901833740856784"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto1.similarity(texto3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlp_spacy\\lib\\runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Doc.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6686739425930707"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto1.similarity(texto4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gato é 100 similar a gato\n",
      "gato é 45 similar a cachorro\n",
      "gato é 30 similar a cavalo\n",
      "gato é 11 similar a pessoa\n",
      "cachorro é 45 similar a gato\n",
      "cachorro é 100 similar a cachorro\n",
      "cachorro é 56 similar a cavalo\n",
      "cachorro é 31 similar a pessoa\n",
      "cavalo é 30 similar a gato\n",
      "cavalo é 56 similar a cachorro\n",
      "cavalo é 100 similar a cavalo\n",
      "cavalo é 32 similar a pessoa\n",
      "pessoa é 11 similar a gato\n",
      "pessoa é 31 similar a cachorro\n",
      "pessoa é 32 similar a cavalo\n",
      "pessoa é 100 similar a pessoa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\nlp_spacy\\lib\\runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlp_spacy\\lib\\runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlp_spacy\\lib\\runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlp_spacy\\lib\\runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlp_spacy\\lib\\runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlp_spacy\\lib\\runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlp_spacy\\lib\\runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlp_spacy\\lib\\runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlp_spacy\\lib\\runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlp_spacy\\lib\\runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlp_spacy\\lib\\runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\nlp_spacy\\lib\\runpy.py:193: ModelsWarning: [W007] The model you're using has no word vectors loaded, so the result of the Token.similarity method will be based on the tagger, parser and NER, which may not give useful similarity judgements. This may happen if you're using one of the small models, e.g. `en_core_web_sm`, which don't ship with word vectors and only use context-sensitive tensors. You can always add your own word vectors, or use one of the larger models instead if available.\n",
      "  \"__main__\", mod_spec)\n"
     ]
    }
   ],
   "source": [
    "texto = pln('gato cachorro cavalo pessoa')\n",
    "for texto1 in texto:\n",
    "    # print('------', texto1)\n",
    "    for texto2 in texto:\n",
    "        # print(texto2)\n",
    "        similaridade = int(texto1.similarity(texto2) * 100)\n",
    "        print(f'{texto1} é {similaridade} similar a {texto2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa 8: Tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estou\n",
      "aprendendo\n",
      "processamento\n",
      "de\n",
      "linguagem\n",
      "natural\n",
      ",\n",
      "curso\n",
      "Curitiba\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
